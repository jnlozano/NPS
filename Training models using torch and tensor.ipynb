{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9ffc623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn #for predictive modeling\n",
    "from patsy import dmatrices #for R-like formulas. https://patsy.readthedocs.io/en/latest/\n",
    "import seaborn as sns #for better graphics\n",
    "sns.set() #better matplotlib defaults\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a270edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data'\n",
    "s = requests.get(url).content\n",
    "df = pd.read_csv(io.StringIO(s.decode('utf-8')), header=None)\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,[11,35]], df.iloc[:,60]=='M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215c3c1d",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43e2ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Performance of hidden layer combo: (1, 8)\n",
      "ROC AUC:  0.6118518518518519\n",
      "Average Precision:  0.5851484238581013\n",
      "Accuracy:  0.6153846153846154\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (4, 1)\n",
      "ROC AUC:  0.5562962962962963\n",
      "Average Precision:  0.5501628001628002\n",
      "Accuracy:  0.5576923076923077\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (2, 1)\n",
      "ROC AUC:  0.6118518518518519\n",
      "Average Precision:  0.5851484238581013\n",
      "Accuracy:  0.6153846153846154\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (8,)\n",
      "ROC AUC:  0.6577777777777778\n",
      "Average Precision:  0.6275946275946276\n",
      "Accuracy:  0.6538461538461539\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (16,)\n",
      "ROC AUC:  0.5762962962962963\n",
      "Average Precision:  0.5627044423340719\n",
      "Accuracy:  0.5769230769230769\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (8, 4)\n",
      "ROC AUC:  0.7333333333333333\n",
      "Average Precision:  0.6948160535117057\n",
      "Accuracy:  0.7307692307692307\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (16, 8)\n",
      "ROC AUC:  0.5562962962962963\n",
      "Average Precision:  0.5501628001628002\n",
      "Accuracy:  0.5576923076923077\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (32, 16)\n",
      "ROC AUC:  0.6474074074074074\n",
      "Average Precision:  0.6083231583231583\n",
      "Accuracy:  0.6538461538461539\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (64, 32)\n",
      "ROC AUC:  0.6318518518518519\n",
      "Average Precision:  0.5995251661918328\n",
      "Accuracy:  0.6346153846153846\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (32,)\n",
      "ROC AUC:  0.6162962962962963\n",
      "Average Precision:  0.5907977207977209\n",
      "Accuracy:  0.6153846153846154\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (4, 4)\n",
      "ROC AUC:  0.6333333333333333\n",
      "Average Precision:  0.6016483516483517\n",
      "Accuracy:  0.6346153846153846\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (10, 10)\n",
      "ROC AUC:  0.5562962962962963\n",
      "Average Precision:  0.5501628001628002\n",
      "Accuracy:  0.5576923076923077\n",
      "====================================================\n",
      "Testing Performance of hidden layer combo: (2, 8)\n",
      "ROC AUC:  0.5962962962962963\n",
      "Average Precision:  0.5762108262108263\n",
      "Accuracy:  0.5961538461538461\n",
      "====================================================\n",
      "\n",
      "\n",
      "Best combined performance score: 2.15891861761427\n",
      "Best combo: (8, 4)\n"
     ]
    }
   ],
   "source": [
    "#3,4 = .61\n",
    "#1,8 = .76\n",
    "#2,8 = .73\n",
    "#2,1 = .71\n",
    "\n",
    "layers = [\n",
    "    (1,8), (4, 1), (2,1), (8,), (16,), (8, 4), (16, 8), (32, 16), (64, 32), (32,), (4, 4), (10, 10), (2,8)]\n",
    "metric_names = [\"ROC AUC\", \"Average Precision\", \"Accuracy\"]\n",
    "bestcombo = None\n",
    "performance = 0 \n",
    "for layer in layers:\n",
    "    combined_score = 0\n",
    "    model = MLPClassifier(solver='lbfgs', max_iter=6000, hidden_layer_sizes=layer, activation='logistic', alpha=0, random_state=0)\n",
    "    print(f\"Testing Performance of hidden layer combo: {layer}\") \n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    for i, metric in enumerate([roc_auc_score, average_precision_score, accuracy_score]):\n",
    "        print(f\"{metric_names[i]}:  {metric(y_test, model.predict(X_test))}\")\n",
    "        combined_score += metric(y_test, model.predict(X_test))\n",
    "    print(\"====================================================\")\n",
    "    if combined_score > performance:\n",
    "        performance = combined_score\n",
    "        best = layer\n",
    "print(f\"\\n\\nBest combined performance score: {performance}\\nBest combo: {best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aef9c1",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57e1d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57aa5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# Download data from open datasets. https://www.kaggle.com/datasets/apollo2506/eurosat-dataset\n",
    "sat_data = datasets.EuroSAT(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "#label dictionary (taken from Kaggle link above)\n",
    "label2int= sat_data.find_classes('data/eurosat/2750/')[1]\n",
    "int2label = dict(zip(label2int.values(),label2int.keys()))\n",
    "\n",
    "train_size =.8\n",
    "test_size = .2\n",
    "torch.manual_seed(0)\n",
    "train_size = round(.8*len(sat_data))\n",
    "training_data, testing_data = torch.utils.data.random_split(sat_data, [train_size, len(sat_data)-train_size])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(testing_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7301d69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.306333  [    0/21600]\n",
      "loss: 2.297401  [ 6400/21600]\n",
      "loss: 2.295554  [12800/21600]\n",
      "loss: 2.293629  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 10.8%, Avg loss: 2.297738 \n",
      "\n",
      "Epoch ran in 22.95 seconds\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.299218  [    0/21600]\n",
      "loss: 2.295014  [ 6400/21600]\n",
      "loss: 2.291018  [12800/21600]\n",
      "loss: 2.288434  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 12.6%, Avg loss: 2.293866 \n",
      "\n",
      "Epoch ran in 13.99 seconds\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 2.293493  [    0/21600]\n",
      "loss: 2.293061  [ 6400/21600]\n",
      "loss: 2.287035  [12800/21600]\n",
      "loss: 2.283624  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 10.8%, Avg loss: 2.289916 \n",
      "\n",
      "Epoch ran in 15.58 seconds\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 2.288116  [    0/21600]\n",
      "loss: 2.290387  [ 6400/21600]\n",
      "loss: 2.283050  [12800/21600]\n",
      "loss: 2.278276  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 9.9%, Avg loss: 2.285771 \n",
      "\n",
      "Epoch ran in 15.89 seconds\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 2.282076  [    0/21600]\n",
      "loss: 2.287831  [ 6400/21600]\n",
      "loss: 2.279124  [12800/21600]\n",
      "loss: 2.272753  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 10.3%, Avg loss: 2.281329 \n",
      "\n",
      "Epoch ran in 16.27 seconds\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 2.275902  [    0/21600]\n",
      "loss: 2.284907  [ 6400/21600]\n",
      "loss: 2.274903  [12800/21600]\n",
      "loss: 2.266297  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 14.1%, Avg loss: 2.276201 \n",
      "\n",
      "Epoch ran in 15.64 seconds\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.268428  [    0/21600]\n",
      "loss: 2.281349  [ 6400/21600]\n",
      "loss: 2.270231  [12800/21600]\n",
      "loss: 2.258462  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 15.1%, Avg loss: 2.270021 \n",
      "\n",
      "Epoch ran in 15.59 seconds\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.259136  [    0/21600]\n",
      "loss: 2.276804  [ 6400/21600]\n",
      "loss: 2.264826  [12800/21600]\n",
      "loss: 2.248793  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 13.4%, Avg loss: 2.262424 \n",
      "\n",
      "Epoch ran in 15.56 seconds\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 2.247576  [    0/21600]\n",
      "loss: 2.271048  [ 6400/21600]\n",
      "loss: 2.258390  [12800/21600]\n",
      "loss: 2.236906  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 12.5%, Avg loss: 2.253155 \n",
      "\n",
      "Epoch ran in 15.77 seconds\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.233595  [    0/21600]\n",
      "loss: 2.263738  [ 6400/21600]\n",
      "loss: 2.250920  [12800/21600]\n",
      "loss: 2.223213  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 12.0%, Avg loss: 2.242385 \n",
      "\n",
      "Epoch ran in 15.60 seconds\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.217831  [    0/21600]\n",
      "loss: 2.254978  [ 6400/21600]\n",
      "loss: 2.242301  [12800/21600]\n",
      "loss: 2.207737  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 11.9%, Avg loss: 2.229836 \n",
      "\n",
      "Epoch ran in 15.37 seconds\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 2.200835  [    0/21600]\n",
      "loss: 2.244237  [ 6400/21600]\n",
      "loss: 2.231997  [12800/21600]\n",
      "loss: 2.190819  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 11.9%, Avg loss: 2.215166 \n",
      "\n",
      "Epoch ran in 15.89 seconds\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 2.183029  [    0/21600]\n",
      "loss: 2.230760  [ 6400/21600]\n",
      "loss: 2.219445  [12800/21600]\n",
      "loss: 2.171467  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 13.8%, Avg loss: 2.197207 \n",
      "\n",
      "Epoch ran in 15.77 seconds\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.163463  [    0/21600]\n",
      "loss: 2.213346  [ 6400/21600]\n",
      "loss: 2.203776  [12800/21600]\n",
      "loss: 2.148634  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 18.8%, Avg loss: 2.175497 \n",
      "\n",
      "Epoch ran in 15.89 seconds\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 2.140954  [    0/21600]\n",
      "loss: 2.191952  [ 6400/21600]\n",
      "loss: 2.185144  [12800/21600]\n",
      "loss: 2.121608  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 21.4%, Avg loss: 2.149892 \n",
      "\n",
      "Epoch ran in 15.92 seconds\n",
      "Done!\n",
      "The more hidden layers I used with smaller outputs (256->128->64->32), the worse the accuracy got. \n",
      "I did try adding layers of both smaller and larger dimensions but found it difficult to determine one that gave better performance. I kept most of my attempts commented out in the model\n"
     ]
    }
   ],
   "source": [
    "# use cpu or gpu device if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define model\n",
    "# Download data from open datasets. https://www.kaggle.com/datasets/apollo2506/eurosat-dataset\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(64*64*3, 1024), #(w x h x c, output_dim). nn.# Changing this to 1024 gave >11.0%\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128), # ending in 64 gave 16.5% accuracy\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(64, 32),\n",
    "            #nn.ReLU(),\n",
    "            #nn.Linear(256, 256), #adding this gave <11.0\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10) #hidden layer of dimension 256 -> output layer of size 10 (the number of classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) #flatten the 64 x 64 x 3 tensor to a 64*64*3 length tensor with 1 dimension.\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "#print(model)\n",
    "loss_fn = nn.CrossEntropyLoss() #the appropriate loss function for multilabel problems.\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # Optimize the parameters of the models using SGD. Set the learning rate/step length.\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer): #a function to train the model\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # compute the gradient and take an SGD step.\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() #MLers also call computing the gradient \"back propagation\". Hence the \"backward()\" function to compute the gradient\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "            \n",
    "def test(dataloader, model, loss_fn): #a function to compute the testing loss\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "\n",
    "torch.manual_seed(0)\n",
    "epochs = 15 # I was testing with ~5 epochs since Im on CPU without NVIDIA\n",
    "for t in range(epochs):\n",
    "    start = time.time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    print(f'Epoch ran in {time.time() - start :.2f} seconds')\n",
    "print(\"Done!\")\n",
    "\n",
    "print(\"The more hidden layers I used with smaller outputs (256->128->64->32), the worse the accuracy got. \")\n",
    "print(\"I did try adding layers of both smaller and larger dimensions but found it difficult to determine one that gave better performance. I kept most of my attempts commented out in the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9ea1c8",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c65a0b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.700430  [    0/21600]\n",
      "loss: 0.610472  [ 6400/21600]\n",
      "loss: 0.513053  [12800/21600]\n",
      "loss: 0.466762  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.416606 \n",
      "\n",
      "Epoch ran in 11.28 seconds\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.589735  [    0/21600]\n",
      "loss: 0.410958  [ 6400/21600]\n",
      "loss: 0.350745  [12800/21600]\n",
      "loss: 0.435327  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.372260 \n",
      "\n",
      "Epoch ran in 11.26 seconds\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.661552  [    0/21600]\n",
      "loss: 0.401046  [ 6400/21600]\n",
      "loss: 0.340504  [12800/21600]\n",
      "loss: 0.434311  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.368157 \n",
      "\n",
      "Epoch ran in 11.99 seconds\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.667031  [    0/21600]\n",
      "loss: 0.398837  [ 6400/21600]\n",
      "loss: 0.336928  [12800/21600]\n",
      "loss: 0.430699  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.364642 \n",
      "\n",
      "Epoch ran in 12.50 seconds\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.662285  [    0/21600]\n",
      "loss: 0.396415  [ 6400/21600]\n",
      "loss: 0.333675  [12800/21600]\n",
      "loss: 0.426614  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.361024 \n",
      "\n",
      "Epoch ran in 13.05 seconds\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.656231  [    0/21600]\n",
      "loss: 0.393908  [ 6400/21600]\n",
      "loss: 0.330232  [12800/21600]\n",
      "loss: 0.422251  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.357108 \n",
      "\n",
      "Epoch ran in 12.79 seconds\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.649528  [    0/21600]\n",
      "loss: 0.391279  [ 6400/21600]\n",
      "loss: 0.326536  [12800/21600]\n",
      "loss: 0.417433  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.352845 \n",
      "\n",
      "Epoch ran in 12.85 seconds\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.642155  [    0/21600]\n",
      "loss: 0.388467  [ 6400/21600]\n",
      "loss: 0.322558  [12800/21600]\n",
      "loss: 0.412185  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.348279 \n",
      "\n",
      "Epoch ran in 12.78 seconds\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.634236  [    0/21600]\n",
      "loss: 0.385510  [ 6400/21600]\n",
      "loss: 0.318197  [12800/21600]\n",
      "loss: 0.406264  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.343102 \n",
      "\n",
      "Epoch ran in 13.06 seconds\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.625188  [    0/21600]\n",
      "loss: 0.382308  [ 6400/21600]\n",
      "loss: 0.313262  [12800/21600]\n",
      "loss: 0.399778  [19200/21600]\n",
      "Test Error: \n",
      " Accuracy: 91.0%, Avg loss: 0.337388 \n",
      "\n",
      "Epoch ran in 12.78 seconds\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# use cpu or gpu device if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(64*64*3, 512), #(w x h x c, output_dim). nn.Linear gives fully connected layers. \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512), #hidden layer of dimension 512 -> hidden layer of dimension 512\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256), #hidden layer of dimension 512 -> hidden layer of dimension 256\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 1) #hidden layer of dimension 256 -> Changed output to 1 since binary classification\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) #flatten the 64 x 64 x 3 tensor to a 64*64*3 length tensor with 1 dimension.\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "     \n",
    "model = NeuralNetwork().to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss() #changed to binary logits loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # Optimize the parameters of the models using SGD. Set the learning rate/step length.\n",
    "\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer): #a function to train the model\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_ind = (y==4).float() #Determine if label is 4 (industrial)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X).squeeze(1)#.unsqueeze() #change loss function to squeeze. From lecture \n",
    "        #from this forum: https://stackoverflow.com/questions/57798033/valueerror-target-size-torch-size16-must-be-the-same-as-input-size-torch\n",
    "        loss = loss_fn(pred, y_ind) \n",
    "\n",
    "        # compute the gradient and take an SGD step.\n",
    "        optimizer.zero_grad() \n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test(dataloader, model, loss_fn): #a function to compute the testing loss\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_ind = (y==4).float()\n",
    "            pred = model(X).squeeze(1)\n",
    "            test_loss += loss_fn(pred, y_ind).item() #change loss function to squeeze. From lecture \n",
    "            correct += ((pred >= 0.0) == y_ind).type(torch.float).sum().item() #changed pred to >= 0.0 to map sigmoid func\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "epochs = 10 # 10 epochs since Im on CPU without NVIDIA\n",
    "for t in range(epochs):\n",
    "    start = time.time()\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "    print(f'Epoch ran in {time.time() - start :.2f} seconds')\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "becda38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24a2743fc70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "model.eval() #we're no longer training the model. Put it into \"evaluate\" mode (as opposed to \"train\" mode). This only affects some layers, like dropout.\n",
    "test_predictions = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for X,y in test_dataloader:\n",
    "        X.to(device)\n",
    "        test_predictions += [model(X.to(device)).squeeze(1) >= 0.0] #changed to sigmoid\n",
    "        test_labels += [(y==4)]\n",
    "test_predictions = torch.cat(test_predictions)\n",
    "test_labels = torch.cat(test_labels)\n",
    "\n",
    "c_mat = confusion_matrix(test_labels, test_predictions.cpu()) #move the predictions from the gpu to the cpu, if they're on a gpu\n",
    "ConfusionMatrixDisplay(c_mat, display_labels=[\"Industrail\",\"Non-Industrial\"]).plot(xticks_rotation='vertical')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
